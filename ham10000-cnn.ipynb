{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":12697862,"sourceType":"datasetVersion","datasetId":7994082},{"sourceId":523650,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":411260,"modelId":429085},{"sourceId":525016,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":411887,"modelId":429684}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"model train","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nimport timm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\n\nmetadata_csv = \"/data/raw/HAM10000/metadata.csv\"\nimage_dir = \"/data/raw/HAM10000/metadata/img\"\nbatch_size = 16\nnum_epochs = 50\nlearning_rate = 1e-3\npatience = 15\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif os.path.isdir(metadata_csv):\n    guess = os.path.join(metadata_csv, \"HAM10000_metadata.csv\")\n    if os.path.exists(guess):\n        metadata_csv = guess\n\n\nlabel_map = {\n    'akiec': 0,\n    'bcc':   1,\n    'bkl':   2,\n    'df':    3,\n    'mel':   4,\n    'nv':    5,\n    'vasc':  6\n}\nidx_to_label = {v: k for k, v in label_map.items()}\n\n\ndf = pd.read_csv(metadata_csv)\ndf = df[df['dx'].isin(label_map.keys())].copy()\ndf['label'] = df['dx'].map(label_map)\ndf['path']  = df['image_id'].apply(lambda x: os.path.join(image_dir, f\"{x}.jpg\"))\n\ndf = df[df['path'].apply(os.path.exists)].reset_index(drop=True)\n\ntrain_df, val_df = train_test_split(\n    df, test_size=0.2, stratify=df['label'], random_state=42\n)\n\nclass SkinDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row['path']).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        label = int(row['label'])\n        return img, label\n\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((300, 300)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(12),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((300, 300)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\n\ntrain_dataset = SkinDataset(train_df, transform=train_transforms)\nval_dataset   = SkinDataset(val_df,   transform=val_transforms)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n\n\n# CLASS WEIGHTS\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_df['label']),\n    y=train_df['label']\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float, device=device)\n\n# MODEL\nmodel = timm.create_model('efficientnet_b3', pretrained=True)\nmodel.classifier = nn.Linear(model.classifier.in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.3, patience=5, verbose=True)\n\n# Mixed precision\nscaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n\n\n# TRAINING LOOP\n\nbest_val_acc = 0.0\nepochs_no_improve = 0\ntrain_acc_history, val_acc_history = [], []\ntrain_loss_history, val_loss_history = [], []\n\nfor epoch in range(num_epochs):\n    print(f\"\\n— Epoch {epoch+1}/{num_epochs} —\")\n\n    #TRAIN\n    model.train()\n    running_corrects, running_loss, n_train = 0, 0.0, 0\n    for inputs, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        _, preds = torch.max(outputs, 1)\n        running_corrects += torch.sum(preds == labels).item()\n        running_loss += loss.item() * inputs.size(0)\n        n_train += inputs.size(0)\n\n    train_acc = running_corrects / max(1, n_train)\n    train_loss = running_loss / max(1, n_train)\n    train_acc_history.append(train_acc)\n    train_loss_history.append(train_loss)\n\n    #VALIDATE\n    model.eval()\n    val_corrects, val_loss_sum, n_val = 0, 0.0, 0\n    all_labels, all_preds, all_probs = [], [], []\n    with torch.no_grad():\n        for inputs, labels in tqdm(val_loader, desc=\"Validating\", leave=False):\n            inputs, labels = inputs.to(device), labels.to(device)\n            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n            probs = torch.softmax(outputs, dim=1)\n            _, preds = torch.max(outputs, 1)\n\n            val_corrects += torch.sum(preds == labels).item()\n            val_loss_sum += loss.item() * inputs.size(0)\n            n_val += inputs.size(0)\n\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_probs.extend(probs.detach().cpu().numpy())\n\n    val_acc = val_corrects / max(1, n_val)\n    val_loss = val_loss_sum / max(1, n_val)\n    val_acc_history.append(val_acc)\n    val_loss_history.append(val_loss)\n\n    scheduler.step(val_acc)  # ReduceLROnPlateau monitors val_acc\n\n    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n    print(f\"Epoch {epoch+1} completed\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save({\n            \"epoch\": epoch + 1,\n            \"model_state_dict\": model.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n            \"val_acc\": best_val_acc,\n            \"label_map\": label_map\n        }, \"best_model.pth\")\n        print(\"model updated\")\n\n        epochs_no_improve = 0\n    else:\n        epochs_no_improve += 1\n\n    # Early stopping\n    if epochs_no_improve >= patience:\n        print(\"Early stopping\")\n        break\n\n\n# PLOTS\nplt.figure(figsize=(10,4))\nplt.plot(train_acc_history, label=\"Train Acc\")\nplt.plot(val_acc_history, label=\"Val Acc\")\nplt.title(\"Accuracy\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Acc\"); plt.legend(); plt.show()\n\nplt.figure(figsize=(10,4))\nplt.plot(train_loss_history, label=\"Train Loss\")\nplt.plot(val_loss_history, label=\"Val Loss\")\nplt.title(\"Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.show()\n\n\nckpt = torch.load(\"best_model.pth\", map_location=device)\nmodel.load_state_dict(ckpt[\"model_state_dict\"])\nmodel.eval()\n\nall_labels, all_preds, all_probs = [], [], []\nwith torch.no_grad():\n    for inputs, labels in tqdm(val_loader, desc=\"Final Eval\", leave=False):\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        probs = torch.softmax(outputs, dim=1)\n        _, preds = torch.max(outputs, 1)\n\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(preds.cpu().numpy())\n        all_probs.extend(probs.cpu().numpy())\n\n\n# METRICS & VISUALS\nprint(\"\\n— Classification Report (Validation, best checkpoint) —\")\ntarget_names = [idx_to_label[i] for i in range(num_classes)]\nprint(classification_report(all_labels, all_preds, target_names=target_names, digits=4))\n\n# Confusion Matrix\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=target_names, yticklabels=target_names)\nplt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(\"Confusion Matrix (Val)\"); plt.show()\n\n# ROC Curves (One-vs-Rest)\nall_probs = np.array(all_probs)\ny_true_bin = np.zeros((len(all_labels), num_classes))\nfor i, label in enumerate(all_labels):\n    y_true_bin[i, label] = 1\n\nplt.figure(figsize=(8,6))\nfor i, class_name in enumerate(target_names):\n    fpr, tpr, _ = roc_curve(y_true_bin[:, i], all_probs[:, i])\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr,\n label=f\"{class_name} (AUC = {roc_auc:.2f})\")\nplt.plot([0,1], [0,1], '--', color='gray')\nplt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curves (Val)\"); plt.legend(); plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Test mel sev acc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport timm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport cv2\n\n\nmetadata_csv = \"/data/raw/HAM10000/metadata.csv\"\nimage_dir = \"/data/raw/HAM10000/metadata/img\"\nmodel_path = \"/data/models/HAM10000\"\nbatch_size = 32\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nseverity_map = {'mild': 0, 'moderate': 1, 'severe': 2}\nidx_to_severity = {v: k for k, v in severity_map.items()}\nnum_classes = 3\n\ndisease_names = {\n    'mel': 'Melanoma', \n    'bcc': 'Basal Cell Carcinoma', \n    'akiec': 'Actinic Keratoses',\n    'bkl': 'Benign Keratosis', \n    'df': 'Dermatofibroma', \n    'nv': 'Melanocytic Nevus', \n    'vasc': 'Vascular Lesion'\n}\n\nif os.path.isdir(metadata_csv):\n    guess = os.path.join(metadata_csv, \"HAM10000_metadata.csv\")\n    if os.path.exists(guess):\n        metadata_csv = guess\n\n\ndef analyze_image_features(image_path):\n    try:\n        img = cv2.imread(image_path)\n        if img is None:\n            return {'area': 0, 'irregularity': 0, 'darkness': 0, 'color_variance': 0}\n        \n        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        \n        _, thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n        contours, _ = cv2.findContours(255 - thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        if contours:\n            largest_contour = max(contours, key=cv2.contourArea)\n            area = cv2.contourArea(largest_contour)\n            perimeter = cv2.arcLength(largest_contour, True)\n            if perimeter > 0:\n                irregularity = (perimeter ** 2) / (4 * np.pi * area) if area > 0 else 0\n            else:\n                irregularity = 0\n        else:\n            area = 0\n            irregularity = 0\n        \n        darkness = np.mean(255 - img_gray) / 255.0\n        color_variance = np.std(img_rgb.reshape(-1, 3), axis=0).mean()\n        \n        return {\n            'area': area, \n            'irregularity': irregularity, \n            'darkness': darkness, \n            'color_variance': color_variance\n        }\n    \n    except Exception:\n        return {'area': 0, 'irregularity': 0, 'darkness': 0, 'color_variance': 0}\n\n\ndef assign_severity_based_on_features(features):\n    area_score = min(features['area'] / 10000, 1.0)\n    irregularity_score = min(features['irregularity'] / 5.0, 1.0)\n    darkness_score = features['darkness']\n    color_variance_score = min(features['color_variance'] / 50.0, 1.0)\n    \n    severity_score = (area_score * 0.3 + irregularity_score * 0.3 + \n                     darkness_score * 0.2 + color_variance_score * 0.2)\n    \n    if severity_score < 0.33:\n        return 'mild'\n    elif severity_score < 0.66:\n        return 'moderate'\n    else:\n        return 'severe'\n\n\nclass SeverityTestDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row['path']).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        severity_label = int(row['severity_label'])\n        return img, severity_label\n\n\ndef load_severity_model(model_path):\n    print(f\"Loading severity model from {model_path}...\")\n    \n    checkpoint = torch.load(model_path, map_location=device)\n    target_disease = checkpoint.get('target_disease', 'unknown')\n    \n    model = timm.create_model('efficientnet_b2', pretrained=False)\n    model.classifier = nn.Sequential(\n        nn.Dropout(0.3),\n        nn.Linear(model.classifier.in_features, 128),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(128, num_classes)\n    )\n    \n    if \"model_state_dict\" in checkpoint:\n        model.load_state_dict(checkpoint[\"model_state_dict\"])\n    else:\n        model.load_state_dict(checkpoint)\n    \n    model = model.to(device)\n    model.eval()\n    \n    print(\"Severity model loaded successfully\")\n    print(f\"Target disease: {disease_names.get(target_disease, target_disease)}\")\n    if \"val_acc\" in checkpoint:\n        print(f\"Training validation accuracy: {checkpoint['val_acc']:.4f}\")\n    \n    return model, target_disease\n\n\ndef prepare_test_data(target_disease):\n    print(f\"Loading test data for {disease_names.get(target_disease, target_disease)}...\")\n    \n    df = pd.read_csv(metadata_csv)\n    df['path'] = df['image_id'].apply(lambda x: os.path.join(image_dir, f\"{x}.jpg\"))\n    df = df[df['path'].apply(os.path.exists)].reset_index(drop=True)\n    \n    df = df[df['dx'] == target_disease].copy()\n    print(f\"Found {len(df)} images of {disease_names.get(target_disease, target_disease)}\")\n    \n    if len(df) == 0:\n        raise ValueError(f\"No images found for disease: {target_disease}\")\n    \n    print(\"Assigning severity labels...\")\n    features_list = []\n    \n    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Analyzing images\"):\n        features = analyze_image_features(row['path'])\n        severity_score = (min(features['area'] / 10000, 1.0) * 0.3 + \n                        min(features['irregularity'] / 5.0, 1.0) * 0.3 + \n                        features['darkness'] * 0.2 + \n                        min(features['color_variance'] / 50.0, 1.0) * 0.2)\n        features_list.append((idx, severity_score))\n    \n    features_list.sort(key=lambda x: x[1])\n    n_samples = len(df)\n    mild_count = n_samples // 3\n    moderate_count = n_samples // 3\n    severe_count = n_samples - mild_count - moderate_count\n    \n    df['severity'] = 'mild'\n    df['severity_label'] = 0\n    \n    mild_indices = [x[0] for x in features_list[:mild_count]]\n    moderate_indices = [x[0] for x in features_list[mild_count:mild_count+moderate_count]]\n    severe_indices = [x[0] for x in features_list[mild_count+moderate_count:]]\n    \n    df.loc[mild_indices, 'severity'] = 'mild'\n    df.loc[mild_indices, 'severity_label'] = 0\n    df.loc[moderate_indices, 'severity'] = 'moderate'\n    df.loc[moderate_indices, 'severity_label'] = 1\n    df.loc[severe_indices, 'severity'] = 'severe'\n    df.loc[severe_indices, 'severity_label'] = 2\n    \n    severity_counts = df['severity'].value_counts()\n    print(\"Test data severity distribution:\")\n    for severity, count in severity_counts.items():\n        print(f\"  {severity.capitalize()}: {count} images ({count/len(df)*100:.1f}%)\")\n    \n    return df\n\n\ndef test_severity_model(model, test_loader):\n    model.eval()\n    \n    all_labels = []\n    all_preds = []\n    all_probs = []\n    correct = 0\n    total = 0\n    \n    print(\"Testing severity model...\")\n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = model(inputs)\n            probs = torch.softmax(outputs, dim=1)\n            _, preds = torch.max(outputs, 1)\n            \n            total += labels.size(0)\n            correct += (preds == labels).sum().item()\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n    \n    accuracy = correct / total\n    print(f\"Overall Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    \n    return np.array(all_labels), np.array(all_preds), np.array(all_probs), accuracy\n\n\ndef show_detailed_results(y_true, y_pred, y_probs, accuracy, target_disease):\n    severity_names = ['Mild', 'Moderate', 'Severe']\n    \n    print(f\"\\n{'='*60}\")\n    print(\"DETAILED TEST RESULTS\")\n    print(f\"Disease: {disease_names.get(target_disease, target_disease)}\")\n    print(f\"{'='*60}\")\n    print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    \n    report = classification_report(y_true, y_pred, target_names=severity_names, digits=4)\n    print(\"\\nClassification Report:\")\n    print(report)\n    \n    print(\"\\nPer-Class Accuracy:\")\n    for i, severity in enumerate(severity_names):\n        class_mask = (y_true == i)\n        if np.sum(class_mask) > 0:\n            class_acc = np.sum((y_pred == i) & class_mask) / np.sum(class_mask)\n            class_count = np.sum(class_mask)\n            print(f\"  {severity}: {class_acc:.4f} ({class_acc*100:.1f}%) - {class_count} samples\")\n    \n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=severity_names, yticklabels=severity_names)\n    plt.xlabel(\"Predicted Severity\")\n    plt.ylabel(\"True Severity\")\n    plt.title(f\"Confusion Matrix - {disease_names.get(target_disease, target_disease)} Severity\\nAccuracy: {accuracy:.3f}\")\n    plt.tight_layout()\n    plt.show()\n    \n    print(\"\\nAverage Confidence per Predicted Class:\")\n    for i, severity in enumerate(severity_names):\n        pred_mask = (y_pred == i)\n        if np.sum(pred_mask) > 0:\n            avg_conf = np.mean([y_probs[j][i] for j in range(len(y_probs)) if pred_mask[j]])\n            print(f\"  {severity}: {avg_conf:.4f} ({avg_conf*100:.1f}%)\")\n\n\ndef run_accuracy_test():\n    print(\"Starting Severity Model Accuracy Test...\")\n    print(\"=\"*50)\n    \n    model, target_disease = load_severity_model(model_path)\n    test_df = prepare_test_data(target_disease)\n    \n    test_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    test_dataset = SeverityTestDataset(test_df, transform=test_transforms)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, \n                            shuffle=False, num_workers=0, pin_memory=True)\n    \n    y_true, y_pred, y_probs, accuracy = test_severity_model(model, test_loader)\n    show_detailed_results(y_true, y_pred, y_probs, accuracy, target_disease)\n    \n    results = {\n        'accuracy': accuracy,\n        'y_true': y_true,\n        'y_pred': y_pred,\n        'y_probs': y_probs,\n        'target_disease': target_disease\n    }\n    \n    np.savez(f'severity_test_results_{target_disease}.npz', **results)\n    print(f\"\\nResults saved to: severity_test_results_{target_disease}.npz\")\n    \n    return accuracy, results\n\n\nif __name__ == \"__main__\":\n    print(\"Severity Model Accuracy Tester\")\n    print(\"=\"*40)\n    print(f\"Using device: {device}\")\n    print(f\"Model path: {model_path}\")\n    print(\"=\"*40)\n    \n    try:\n        accuracy, results = run_accuracy_test()\n        print(f\"\\nTesting completed!\")\n        print(f\"Final accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)\")\n        \n    except FileNotFoundError as e:\n        print(f\"File not found: {e}\")\n        print(\"Please check your model path and data paths\")\n        \n    except Exception as e:\n        print(f\"Error during testing: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test model acc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport timm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\n\nmetadata_csv = \"/data/raw/HAM10000/metadata.csv\"\nimage_dir = \"/data/raw/HAM10000/metadata/img\"\nmodel_path = \"/data/models/HAM10000\"\nbatch_size = 32\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif os.path.isdir(metadata_csv):\n    guess = os.path.join(metadata_csv, \"ISIC2018_Task3_Test_GroundTruth.csv\")\n    if os.path.exists(guess):\n        metadata_csv = guess\n\nlabel_map = {\n    'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3,\n    'mel': 4, 'nv': 5, 'vasc': 6\n}\nidx_to_label = {v: k for k, v in label_map.items()}\nnum_classes = len(label_map)\n\n\nclass SkinDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row['path']).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        label = int(row['label'])\n        return img, label\n\n\ndef load_test_data():\n    df = pd.read_csv(metadata_csv)\n    df = df[df['dx'].isin(label_map.keys())].copy()\n    df['label'] = df['dx'].map(label_map)\n    df['path'] = df['image_id'].apply(lambda x: os.path.join(image_dir, f\"{x}.jpg\"))\n    df = df[df['path'].apply(os.path.exists)].reset_index(drop=True)\n    \n    print(f\"Total samples available: {len(df)}\")\n    print(\"Class distribution:\")\n    for label, count in df['dx'].value_counts().items():\n        print(f\"  {label}: {count}\")\n    \n    return df\n\n\ndef load_trained_model(model_path):\n    print(f\"Loading model from {model_path}...\")\n    \n    model = timm.create_model('efficientnet_b3', pretrained=False)\n    model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n    \n    checkpoint = torch.load(model_path, map_location=device)\n    \n    print(f\"Available keys in checkpoint: {list(checkpoint.keys())}\")\n    \n    if \"model_state_dict\" in checkpoint:\n        model.load_state_dict(checkpoint[\"model_state_dict\"])\n    elif \"state_dict\" in checkpoint:\n        model.load_state_dict(checkpoint[\"state_dict\"])\n    elif \"model\" in checkpoint:\n        model.load_state_dict(checkpoint[\"model\"])\n    else:\n        try:\n            model.load_state_dict(checkpoint)\n        except Exception as e:\n            print(f\"Error loading model: {e}\")\n            print(\"Please check your model file format\")\n            return None\n    \n    model = model.to(device)\n    model.eval()\n    \n    print(\"Model loaded successfully\")\n    \n    for key in [\"val_acc\", \"validation_accuracy\", \"best_acc\", \"accuracy\"]:\n        if key in checkpoint:\n            print(f\"Training validation accuracy: {checkpoint[key]:.4f}\")\n            break\n    \n    return model\n\n\ndef test_model(model, test_loader):\n    model.eval()\n    \n    all_labels = []\n    all_preds = []\n    all_probs = []\n    correct = 0\n    total = 0\n    \n    print(\"Testing model...\")\n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = model(inputs)\n            probs = torch.softmax(outputs, dim=1)\n            _, preds = torch.max(outputs, 1)\n            \n            total += labels.size(0)\n            correct += (preds == labels).sum().item()\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n    \n    accuracy = correct / total\n    print(f\"Overall Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    \n    return np.array(all_labels), np.array(all_preds), np.array(all_probs), accuracy\n\n\ndef show_results(y_true, y_pred, accuracy):\n    target_names = [idx_to_label[i] for i in range(num_classes)]\n    \n    print(f\"\\n{'='*50}\")\n    print(\"DETAILED TEST RESULTS\")\n    print(f\"{'='*50}\")\n    print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    print(\"\\nPer-class Results:\")\n    \n    report = classification_report(y_true, y_pred, target_names=target_names, \n                                 digits=4, output_dict=True)\n    \n    for i, class_name in enumerate(target_names):\n        if str(i) in report:\n            precision = report[str(i)]['precision']\n            recall = report[str(i)]['recall']\n            f1 = report[str(i)]['f1-score']\n            support = report[str(i)]['support']\n            print(f\"  {class_name:6}: Precision={precision:.3f}, Recall={recall:.3f}, \"\n                  f\"F1={f1:.3f}, Support={support}\")\n    \n    print(f\"\\nMacro avg: Precision={report['macro avg']['precision']:.3f}, \"\n          f\"Recall={report['macro avg']['recall']:.3f}, \"\n          f\"F1={report['macro avg']['f1-score']:.3f}\")\n    \n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=target_names, yticklabels=target_names)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(f\"Confusion Matrix\\nOverall Accuracy: {accuracy:.3f}\")\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n\n\ndef run_test():\n    df = load_test_data()\n    \n    test_transforms = transforms.Compose([\n        transforms.Resize((300, 300)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    test_dataset = SkinDataset(df, transform=test_transforms)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, \n                           shuffle=False, num_workers=2, pin_memory=True)\n    \n    model = load_trained_model(model_path)\n    \n    y_true, y_pred, y_probs, accuracy = test_model(model, test_loader)\n    \n    show_results(y_true, y_pred, accuracy)\n    \n    return accuracy, y_true, y_pred, y_probs\n\n\nif __name__ == \"__main__\":\n    print(\"Starting model test...\")\n    accuracy, y_true, y_pred, y_probs = run_test()\n    print(f\"\\nTesting complete! Final accuracy: {accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"single test img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms\nimport timm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch.nn.functional as F\n\n\nmodel_path = \"/data/models/HAM10000\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nlabel_map = {\n    'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3,\n    'mel': 4, 'nv': 5, 'vasc': 6\n}\n\nidx_to_label = {v: k for k, v in label_map.items()}\n\ndisease_names = {\n    'akiec': 'Actinic Keratoses',\n    'bcc': 'Basal Cell Carcinoma', \n    'bkl': 'Benign Keratosis',\n    'df': 'Dermatofibroma',\n    'mel': 'Melanoma',\n    'nv': 'Melanocytic Nevus',\n    'vasc': 'Vascular Lesion'\n}\n\nnum_classes = len(label_map)\n\n\ndef load_model(model_path):\n    print(f\"Loading model from {model_path}...\")\n    \n    model = timm.create_model('efficientnet_b3', pretrained=False)\n    model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n    \n    checkpoint = torch.load(model_path, map_location=device)\n    \n    if \"model_state_dict\" in checkpoint:\n        model.load_state_dict(checkpoint[\"model_state_dict\"])\n    elif \"state_dict\" in checkpoint:\n        model.load_state_dict(checkpoint[\"state_dict\"])\n    elif \"model\" in checkpoint:\n        model.load_state_dict(checkpoint[\"model\"])\n    else:\n        model.load_state_dict(checkpoint)\n    \n    model = model.to(device)\n    model.eval()\n    \n    print(\"Model loaded successfully\")\n    return model\n\n\ndef preprocess_image(image_path):\n    transform = transforms.Compose([\n        transforms.Resize((300, 300)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    try:\n        image = Image.open(image_path).convert(\"RGB\")\n        original_image = image.copy()\n        input_tensor = transform(image).unsqueeze(0)\n        \n        return input_tensor, original_image\n    \n    except Exception as e:\n        print(f\"Error loading image: {e}\")\n        return None, None\n\n\ndef predict_image(model, image_tensor):\n    with torch.no_grad():\n        image_tensor = image_tensor.to(device)\n        outputs = model(image_tensor)\n        probabilities = F.softmax(outputs, dim=1)\n        _, predicted_class = torch.max(outputs, 1)\n        predicted_class = predicted_class.item()\n        confidence = probabilities[0][predicted_class].item()\n        all_probs = probabilities[0].cpu().numpy()\n        \n    return predicted_class, confidence, all_probs\n\n\ndef display_results(original_image, predicted_class, confidence, all_probs, image_path):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    ax1.imshow(original_image)\n    ax1.axis('off')\n    ax1.set_title(f'Input Image\\n{image_path.split(\"/\")[-1]}', fontsize=12)\n    \n    predicted_label = idx_to_label[predicted_class]\n    predicted_disease = disease_names[predicted_label]\n    \n    class_names = [disease_names[idx_to_label[i]] for i in range(num_classes)]\n    colors = ['red' if i == predicted_class else 'lightblue' for i in range(num_classes)]\n    \n    bars = ax2.barh(range(num_classes), all_probs * 100, color=colors)\n    ax2.set_yticks(range(num_classes))\n    ax2.set_yticklabels(class_names, fontsize=10)\n    ax2.set_xlabel('Confidence (%)', fontsize=12)\n    ax2.set_title('Prediction Confidence for All Classes', fontsize=12)\n    ax2.set_xlim(0, 100)\n    \n    for i, (bar, prob) in enumerate(zip(bars, all_probs)):\n        width = bar.get_width()\n        ax2.text(width + 1, bar.get_y() + bar.get_height()/2, \n                f'{prob*100:.1f}%', ha='left', va='center', fontsize=9)\n    \n    plt.tight_layout()\n    \n    print(f\"\\n{'='*60}\")\n    print(\"PREDICTION RESULTS\")\n    print(f\"{'='*60}\")\n    print(f\"Image: {image_path.split('/')[-1]}\")\n    print(f\"Predicted Class: {predicted_disease} ({predicted_label.upper()})\")\n    print(f\"Confidence: {confidence*100:.2f}%\")\n    print(\"\\nAll Class Probabilities:\")\n    \n    prob_pairs = [(disease_names[idx_to_label[i]], all_probs[i]*100) for i in range(num_classes)]\n    prob_pairs.sort(key=lambda x: x[1], reverse=True)\n    \n    for disease, prob in prob_pairs:\n        indicator = \"<- PREDICTED\" if disease == predicted_disease else \"\"\n        print(f\"   {disease:20}: {prob:5.1f}% {indicator}\")\n    \n    plt.show()\n    \n    return predicted_label, confidence\n\n\ndef test_single_image(image_path, model_path=\"best_model.pth\"):\n    print(f\"Testing image: {image_path}\")\n    \n    model = load_model(model_path)\n    image_tensor, original_image = preprocess_image(image_path)\n    \n    if image_tensor is None:\n        return None, None\n    \n    predicted_class, confidence, all_probs = predict_image(model, image_tensor)\n    predicted_label, confidence = display_results(\n        original_image, predicted_class, confidence, all_probs, image_path\n    )\n    \n    return predicted_label, confidence\n\n\ndef main():\n    image_path = \"your_image.jpg\"\n    \n    try:\n        predicted_label, confidence = test_single_image(image_path)\n        \n        if predicted_label:\n            print(\"\\nTesting complete!\")\n            print(f\"Final prediction: {disease_names[predicted_label]} with {confidence*100:.1f}% confidence\")\n            \n    except FileNotFoundError:\n        print(f\"Image file not found: {image_path}\")\n        print(\"Please update the image_path variable with the correct path to your image\")\n        \n    except Exception as e:\n        print(f\"Error during testing: {e}\")\n\n\ndef interactive_test():\n    print(\"Single Image Skin Lesion Classifier\")\n    print(\"=\" * 40)\n    \n    while True:\n        image_path = input(\"\\nEnter image path (or 'quit' to exit): \").strip()\n        \n        if image_path.lower() in ['quit', 'exit', 'q']:\n            print(\"Goodbye!\")\n            break\n            \n        if not image_path:\n            print(\"Please enter a valid image path\")\n            continue\n            \n        try:\n            predicted_label, confidence = test_single_image(image_path)\n            \n            if predicted_label:\n                print(\"\\nPrediction Summary:\")\n                print(f\"   Disease: {disease_names[predicted_label]}\")\n                print(f\"   Confidence: {confidence*100:.1f}%\")\n                \n        except Exception as e:\n            print(f\"Error: {e}\")\n            \n        print(\"\\n\" + \"-\" * 50)\n\n\nif __name__ == \"__main__\":\n    interactive_test()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}