{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12697862,"sourceType":"datasetVersion","datasetId":7994082},{"sourceId":523650,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":411260,"modelId":429085}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef show_image(title, img):\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.figure(figsize=(6, 6))\n    plt.imshow(img_rgb)\n    plt.title(title)\n    plt.axis(\"off\")\n    plt.show()\n\n\ndef remove_hair(img, kernel_size=9):\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n    _, hair_mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n    inpainted = cv2.inpaint(img, hair_mask, 1, cv2.INPAINT_TELEA)\n    return inpainted, hair_mask\n\n\ndef check_hair_coverage(hair_mask, threshold=0.15):\n    coverage = np.sum(hair_mask > 0) / (hair_mask.shape[0] * hair_mask.shape[1])\n    return coverage, coverage > threshold\n\n\ndef preprocess_skin_image(img, resize_shape=(224, 224), hair_threshold=0.15, debug=False):\n    hair_removed, hair_mask = remove_hair(img)\n    coverage, too_much_hair = check_hair_coverage(hair_mask, hair_threshold)\n    \n    if too_much_hair:\n        print(f\"Too much hair detected ({coverage*100:.1f}%). Please retake the photo with less hair obstruction.\")\n        return None\n    \n    if debug:\n        print(f\"Hair coverage: {coverage*100:.2f}%\")\n        show_image(\"Hair Removed\", hair_removed)\n    \n    final_img = cv2.resize(hair_removed, resize_shape)\n    final_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)\n    final_img = final_img.astype(\"float32\") / 255.0\n    \n    return final_img\n\n\n\nimage_path = \"/data/raw/HAM10000/metadata/img\"\nimg = cv2.imread(image_path)\n\nprocessed_img = preprocess_skin_image(img, debug=True)\n\nif processed_img is not None:\n    plt.imshow(processed_img)\n    plt.title(\"Final Preprocessed Image for ML\")\n    plt.axis(\"off\")\n    plt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}